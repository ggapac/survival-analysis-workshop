---
title: "Survival analysis"
output:
  html_document:
    df_print: paged
---

# Introduction

TO DO: Describe different namings, definition, examples

It is also known as *lifetime data analysis*, *reliability analysis*, *time to event analysis*, and *event history analysis* depending on the type of application.

## Fundamental concepts

$T$ ... non-negative continuous random variable representing the time until the event occurs

$f(t)$ ... probability density function

$F(t) = P(T < t)$ ... cumulative distribution function

$S(t) = P(T \geq t) = 1 - F(t)$ ... survival function

$h(t) =\frac{f(t)}{S(t)}$... hazard rate

$H(t)$ ... cumulative hazard

![](images/Screenshot%202024-03-03%20at%2000.15.39.png)

*Image source: <https://arxiv.org/abs/1708.04649>*

## Censored data

What distinguishes survival analysis from other areas in statistics is the data that are usually censored.

Censored data is **any data for which we do not know the exact event time**.

For a survival problem, the time to the event of interest ($T$) is known precisely only for those instances where the event occurs during the study period.

We distinguish between Type I and Type II censoring:

-   In Type I censoring we observe all individuals for a specific time period or until failure.

-   Type II censoring design can often be found in engineering, where a total of *n* objects are observed and the study ends when *r* of them fail.

Observations can be *point-censored* or *interval-censored*. Let's take a look at point censoring:

![](images/Screenshot%202024-03-09%20at%2011.40.41.png)

Interval censoring is shown in the bottom figure:

![](images/Screenshot%202024-03-09%20at%2011.54.42.png)

## How to handle censored data?

-   **Complete data analysis**: ignore the censored observations.

-   **Imputation**: make (false?) assumptions about censored observations.

-   **Dichotomized data analysis**: binarize the problem, e.g. only focus on whether the event occurred or not.

-   **Likelihood-based approach**: adjust the likelihood based on whether the individual was censored or not. Mind the censoring assumptions!

Now let's get to know our data.

## Veterans' Administration Lung Cancer study

The dataset weâ€™ll be working with today is one that was published in *The Statistical Analysis of Failure Time Data* by Kalbfleisch and Prentice. It is described as follows:

> In this trial, **137** males with advanced inoperable lung cancer were randomized to either a standard or test chemotherapy. The primary endpoint for therapy comparison was time to death. Only 9 of the 137 survival times were censored.

The dataset is made available in the R *survival* package.

```{r}
library(survival)
```

Columns:

-   `trt`: treatment, 1=standard, 2=test
-   `celltype`: histological type of tumor
-   `time`: survival time (in days)
-   `status`: censoring status, 1=death, 0=censored
-   `karno`: Karnofsky performance score (100 means good)
-   `diagtime`: months from diagnosis to treatment
-   `age`: age in years
-   `prior`: prior therapy, 0=no, 10=yes

```{r}
dat <- veteran
summary(veteran)
```

```{r treatment}
# preprocess: standard=0, test=1
dat$trt <- dat$trt - 1
treatment <- factor(dat$trt, levels=c(0,1), labels=c("standard", "test"))
table(treatment)
```

```{r age}
library(ggplot2)
ggplot(dat, aes(x=age)) + 
    geom_bar() + 
    xlab("age in years") +
    theme_bw()
```

```{r diagtime}
ggplot(dat, aes(diagtime)) +
    geom_bar() + 
    xlab("months from diagnosis to treatment") +
    theme_bw()
```

```{r celltype}
ggplot(dat, aes(x=celltype)) + 
    geom_bar() + 
    xlab("cell type") + 
    theme_bw()
```

```{r prior}
# preprocess, prior therapy 1=yes, 0=no
dat$prior <- dat$prior / 10
prior <- factor(dat$prior, levels=c(0,1), labels=c("no", "yes"))
table(prior)
```

```{r karno}
ggplot(dat, aes(x=karno)) + 
    geom_bar() + 
    xlab("Karnofsky performance score") + 
    scale_x_continuous(breaks = seq(0, 100, by=5)) +
    theme_bw()
```

```{r time}
ggplot(dat, aes(x=time)) + 
    geom_histogram(binwidth=20) + 
    xlab("time [days]") + 
    theme_bw()
```

```{r status}
status <- factor(dat$status, levels=c(0, 1), labels = c("censored", "death"))
table(status)
```

**Q: What type of censored data are we dealing with?**

In this workshop, we focus on the Type I censoring design, our data is right-censored and we assume non-informative censoring, which means that the distribution of survival times provides no information about the distribution of censorship times and vice versa.

There are better ways to explore survival data. Let's see how.

## Survival curves

Survival functions seem to be the most intuitive for humans.

$S(t) = P(T \geq t) = 1 - F(t)$ ... survival function

Description: *The survival function, S(t), is a measure of the probability of survival or non-occurrence of an event up to time, t.*

More intitive: *The survival function indicates the proportion of a population expected to survive beyond a certain time point, t.*

![](images/example-survival-curve.png)

### Terminology:

-   **Median survival time**: Median survival time is the time at which 50% of the population has experienced the event of interest.

-   

    ------------------------------------------------------------------------

## Kaplan-Meier curves

Let's first familiarize ourselves with Kaplan-Meier curves on a toy example.

| Name    | Time | Event |
|:--------|-----:|------:|
| Anthony |    2 |     1 |
| Bert    |    3 |     1 |
| Chloe   |    3 |     0 |
| David   |    4 |     1 |
| Elle    |    4 |     1 |
| Fay     |    6 |     0 |
| Gabe    |    7 |     1 |
| Harry   |    8 |     0 |
| Irene   |   10 |     0 |
| Noah    |   10 |     1 |

Kaplan-Meier estimator follows the equation:

$\widehat{S}(t) = \prod_{i: t_i \leq t} \left(1 - \frac{d_i}{n_i}\right),$

where $\widehat{S}(0) = 1$.

$d_i$ ... number of events at the time $t_i$

$n_i$ ... number of samples that survived up until $t_i$

### Toy example

Your task is to implement a Kaplan-Meier estimator in R.

```{r echo=T, results='hide'}

time <- c(2, 3, 3, 4, 4, 6, 7, 8, 10, 10)
event <- c(1, 1, 0, 1, 1, 0, 1, 0, 0, 1)

KM_curve <- function(time, event) {
  df <- data.frame(time = time, event = event)
  curve <- data.frame(time = c(0, unique(time)), proba = c(NA))

  S <- 1

  for (i in seq_along(curve$time)) {

    t <- curve$time[i]
    
    d <- sum(df[df$time == t,]$event)
    n <- nrow(df[df$time >= t,])

    S <- S * (1 - d/n)
    curve[i, "proba"] <- S    
  }

  return(curve)
}

curve <- KM_curve(time, event)
```

Use this function to plot the curve:

```{r, fig.width=4, fig.height=3}

plot_survival_curve <- function(curve) {
  ggplot(curve, aes(x = time, y = proba)) +
    geom_step() +
    ylim(0, 1) +
    theme_minimal() +
    labs(x = "Time", y = "Probability", title = "Kaplan-Meier Survival Curve")
}

plot_survival_curve(curve)
```

### Rossi dataset

Now, let's apply our knowledge and functions to our Rossi dataset.

```{r echo=T, results='hide'}

dat <- dat[order(dat$week),]
rossi_curve <- KM_curve(dat$week, dat$arrest)

plot_survival_curve(rossi_curve)
```

What can we conclude?

## Hazard rate

$h(t) =\frac{f(t)}{S(t)}$... hazard rate

The hazard function is the probability that the person dies in the next instant, given that it survived to time t.

$$
h(t) = \lim_{\Delta t \to 0} \frac{P(t \leq T < t + \Delta t | T \geq t)}{\Delta t}
$$

![](images/example-hazard-human.png)

*Image source: <https://www.semanticscholar.org/paper/Nonparametric-Tests-for-Change-Points-in-Hazard-in-Rois/752fc67d89c018bd16d065bdd794943b182fa64e>*

```{r echo=T, results='hide'}
library('stats')

time <- c(2, 3, 3, 4, 4, 6, 7, 8, 10, 10)
event <- c(1, 1, 0, 1, 1, 0, 1, 0, 0, 1)

moving_average <- function(x, n) {
  filter <- rep(1/n, n)
  stats::filter(x, filter, sides = 1, circular = F)
}

hazard_rate_curve <- function(time, event, filter_size) {
  df <- data.frame(time = time, event = event)
  curve <- data.frame(time = c(0, unique(time)), rate = c(NA))

  h <- 0

  for (i in seq_along(curve$time)) {

    t <- curve$time[i]
    
    d <- sum(df[df$time == t,]$event)
    n <- nrow(df[df$time >= t,])

    curve[i, "rate"] <- d/n
  }

  ma <- moving_average(curve$rate, filter_size)
  padding_size <- filter_size - 1
  padded_ma <- c(curve$rate[1:(padding_size)], ma[filter_size:length(curve$rate)])

  curve$rate <- padded_ma
  return(curve)
}

hazard_curve <- hazard_rate_curve(time, event, 3)
```

```{r, fig.width=4, fig.height=3}

plot_hazard_curve <- function(curve) {
  ggplot(curve, aes(x = time, y = rate)) +
    geom_step() +
    theme_minimal() +
    labs(x = "Time", y = "Hazard Rate", title = "Hazard Rate Curve")
}

plot_hazard_curve(hazard_curve)
```

### Rossi dataset

Now, let's apply our knowledge and functions to our Rossi dataset.

```{r echo=T, results='hide'}

dat <- dat[order(dat$week),]
rossi_hazard_curve <- hazard_rate_curve(dat$week, dat$arrest, 7)

plot_hazard_curve(rossi_hazard_curve)
```

What can we conclude?
